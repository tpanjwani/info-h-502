{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern Matching 4 - Video, Matching & Tracking\n",
    "\n",
    "**Objectives**\n",
    "\n",
    "* Analyze video sequences\n",
    "* Match objects between frames for tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video import\n",
    "\n",
    "[Download](https://my.pcloud.com/publink/show?code=XZpIUMkZQX7lwSh8BPpO5vF6UWC6xSXgVLRy) the images from the video sequence, and the supervised segmentation ground truth: \n",
    "\n",
    "(Reference: http://groups.inf.ed.ac.uk/f4k/PAPERS/VIGTA2012.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "from skimage.io import imread\n",
    "import os\n",
    "\n",
    "vid_path = '../data/Video/'\n",
    "gt_path = '../data/GroundTruth/'\n",
    "\n",
    "seq0 = [685,705]\n",
    "seq1 = [1173,1191]\n",
    "\n",
    "for no in range(*seq1):\n",
    "    fid = os.path.join(vid_path,'frame%04d.jpg'%no)\n",
    "    rgb = imread(fid)    \n",
    "    \n",
    "    fid =  os.path.join(gt_path,'%d.png'%no)\n",
    "    supervision = imread(fid)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title('rgb image')\n",
    "    plt.imshow(rgb)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(supervision)\n",
    "    plt.title('ground truth')\n",
    "    break #stop after one frame for test purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background image (Video segmentation)\n",
    "\n",
    "When analyzing video sequences, we can use the *movement of the frame* to help our object segmentation. In this video, our goal is to segment the fish from the background. The background here is the part of the image that doesn't change from frame to frame: detecting the objects can therefore be done using **background subtraction**.\n",
    "\n",
    "Implement the background subtraction algorithm:\n",
    "\n",
    "1. Initialize background image: $B_{0} = I_{0}$ where $I_t$ is the image at time $t$ and $B$ is the estimated background. \n",
    "1. Update background: $B_{t} = \\alpha B_{t-1} + (1-\\alpha) I_t$\n",
    "> What is the purpose of $\\alpha$? How can you determine that your background estimation is \"stable\" and can be used?\n",
    "1. Subtract background to detect foreground: $F_t = I_t - B_t$\n",
    "1. Find a good post-processing to clean-up the foreground image. Label the individual objects (fish).\n",
    "1. Using the supervised part of the sequence, estimate the detection error of your algorithm.\n",
    "> *Hint: useful metrics for segmentation performance include per-pixel accuracy, precision, recall, or F1-score (DICE). These measures can also be made per-object, which is slightly more difficult to compute but in many applications a better indicator of the actual performance of the algorithm.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -- Your code here -- #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object tracking\n",
    "\n",
    "1. Extract interesting features from the detected objects.\n",
    "1. Suggest a method to recognise and track objects from one frame to the next frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -- Your code here -- #\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
